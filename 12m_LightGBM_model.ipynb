{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a60baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import calendar\n",
    "from datetime import date\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97371e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full hourly dataset from merged.csv...\n",
      "Aggregating hourly data to monthly...\n",
      "Aggregation complete. New monthly dataset has 5040 rows.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5040 entries, 0 to 5039\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   group_id      5040 non-null   int64              \n",
      " 1   measured_at   5040 non-null   datetime64[ns, UTC]\n",
      " 2   consumption   5040 non-null   float64            \n",
      " 3   eur_per_mwh   5040 non-null   float64            \n",
      " 4   avg_temp      5040 non-null   float64            \n",
      " 5   avg_hum       5040 non-null   float64            \n",
      " 6   wind          5040 non-null   float64            \n",
      " 7   rain          5040 non-null   float64            \n",
      " 8   air_pressure  5040 non-null   float64            \n",
      " 9   m_area        5040 non-null   object             \n",
      " 10  region        5040 non-null   object             \n",
      " 11  municipality  5040 non-null   object             \n",
      " 12  segment       5040 non-null   object             \n",
      " 13  p_type        5040 non-null   object             \n",
      " 14  c_bucket      5040 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(7), int64(1), object(6)\n",
      "memory usage: 590.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the original hourly data\n",
    "DATA_PATH = \"merged.csv\"\n",
    "TIME_COLUMN = 'measured_at'\n",
    "GROUP_COLUMN = 'group_id'\n",
    "TARGET_COLUMN = 'consumption'\n",
    "\n",
    "print(f\"Loading full hourly dataset from {DATA_PATH}...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[TIME_COLUMN] = pd.to_datetime(df[TIME_COLUMN])\n",
    "\n",
    "# Define our aggregations\n",
    "weather_cols = ['avg_temp', 'avg_hum', 'wind', 'rain', 'air_pressure']\n",
    "price_cols = ['eur_per_mwh']\n",
    "static_cols = ['m_area', 'region', 'municipality', 'segment', 'p_type', 'c_bucket']\n",
    "\n",
    "# Create a dictionary of aggregations\n",
    "aggs = {}\n",
    "aggs[TARGET_COLUMN] = 'sum'\n",
    "for col in price_cols + weather_cols:\n",
    "    aggs[col] = 'mean'\n",
    "for col in static_cols:\n",
    "    aggs[col] = 'first'\n",
    "\n",
    "# Set index and resample\n",
    "print(\"Aggregating hourly data to monthly...\")\n",
    "df = df.set_index(TIME_COLUMN)\n",
    "\n",
    "# Group by group_id, then resample by Month Start ('MS')\n",
    "monthly_df = df.groupby(GROUP_COLUMN).resample('MS').agg(aggs)\n",
    "\n",
    "# Clean up the new DataFrame\n",
    "monthly_df = monthly_df.reset_index()\n",
    "monthly_df = monthly_df.dropna(subset=[TARGET_COLUMN])\n",
    "\n",
    "print(f\"Aggregation complete. New monthly dataset has {len(monthly_df)} rows.\")\n",
    "monthly_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a0e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Monthly Feature Engineering (Direct Strategy) ---\n",
      "Creating time features...\n",
      "Creating lag and rolling features...\n",
      "Creating 12 future-month target columns...\n",
      "--- Monthly Feature Engineering Complete ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5040 entries, 0 to 5039\n",
      "Data columns (total 42 columns):\n",
      " #   Column                     Non-Null Count  Dtype              \n",
      "---  ------                     --------------  -----              \n",
      " 0   group_id                   5040 non-null   int64              \n",
      " 1   measured_at                5040 non-null   datetime64[ns, UTC]\n",
      " 2   consumption                5040 non-null   float64            \n",
      " 3   eur_per_mwh                5040 non-null   float64            \n",
      " 4   avg_temp                   5040 non-null   float64            \n",
      " 5   avg_hum                    5040 non-null   float64            \n",
      " 6   wind                       5040 non-null   float64            \n",
      " 7   rain                       5040 non-null   float64            \n",
      " 8   air_pressure               5040 non-null   float64            \n",
      " 9   m_area                     5040 non-null   category           \n",
      " 10  region                     5040 non-null   category           \n",
      " 11  municipality               5040 non-null   category           \n",
      " 12  segment                    5040 non-null   category           \n",
      " 13  p_type                     5040 non-null   category           \n",
      " 14  c_bucket                   5040 non-null   category           \n",
      " 15  year                       5040 non-null   int32              \n",
      " 16  month_sin                  5040 non-null   float64            \n",
      " 17  month_cos                  5040 non-null   float64            \n",
      " 18  num_holidays               5040 non-null   int64              \n",
      " 19  consumption_lag_1m         4928 non-null   float64            \n",
      " 20  consumption_lag_2m         4816 non-null   float64            \n",
      " 21  consumption_lag_3m         4704 non-null   float64            \n",
      " 22  consumption_lag_12m        3696 non-null   float64            \n",
      " 23  consumption_roll_mean_12m  5040 non-null   float64            \n",
      " 24  eur_per_mwh_lag_12m        3696 non-null   float64            \n",
      " 25  avg_temp_lag_12m           3696 non-null   float64            \n",
      " 26  avg_hum_lag_12m            3696 non-null   float64            \n",
      " 27  wind_lag_12m               3696 non-null   float64            \n",
      " 28  rain_lag_12m               3696 non-null   float64            \n",
      " 29  air_pressure_lag_12m       3696 non-null   float64            \n",
      " 30  target_1m_ahead            4928 non-null   float64            \n",
      " 31  target_2m_ahead            4816 non-null   float64            \n",
      " 32  target_3m_ahead            4704 non-null   float64            \n",
      " 33  target_4m_ahead            4592 non-null   float64            \n",
      " 34  target_5m_ahead            4480 non-null   float64            \n",
      " 35  target_6m_ahead            4368 non-null   float64            \n",
      " 36  target_7m_ahead            4256 non-null   float64            \n",
      " 37  target_8m_ahead            4144 non-null   float64            \n",
      " 38  target_9m_ahead            4032 non-null   float64            \n",
      " 39  target_10m_ahead           3920 non-null   float64            \n",
      " 40  target_11m_ahead           3808 non-null   float64            \n",
      " 41  target_12m_ahead           3696 non-null   float64            \n",
      "dtypes: category(6), datetime64[ns, UTC](1), float64(32), int32(1), int64(2)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting Monthly Feature Engineering (Direct Strategy) ---\")\n",
    "data_full = monthly_df.copy()\n",
    "\n",
    "# Sort for correct lag creation\n",
    "data_full = data_full.sort_values(by=[GROUP_COLUMN, TIME_COLUMN])\n",
    "\n",
    "# Create PREDICTOR Features (Our 'X' variables)\n",
    "print(\"Creating time features...\")\n",
    "data_full['month'] = data_full[TIME_COLUMN].dt.month\n",
    "data_full['year'] = data_full[TIME_COLUMN].dt.year\n",
    "data_full['month_sin'] = np.sin(2 * np.pi * data_full['month'] / 12.0)\n",
    "data_full['month_cos'] = np.cos(2 * np.pi * data_full['month'] / 12.0)\n",
    "\n",
    "fin_holidays = holidays.Finland()\n",
    "def count_holidays_in_month(year, month):\n",
    "    if not (isinstance(year, int) and isinstance(month, int)): return 0\n",
    "    try:\n",
    "        _, num_days = calendar.monthrange(year, month)\n",
    "        count = 0\n",
    "        for day in range(1, num_days + 1):\n",
    "            if date(year, month, day) in fin_holidays:\n",
    "                count += 1\n",
    "        return count\n",
    "    except ValueError:\n",
    "        return 0\n",
    "vectorized_holiday_count = np.vectorize(count_holidays_in_month)\n",
    "data_full['num_holidays'] = vectorized_holiday_count(data_full['year'], data_full['month'])\n",
    "data_full = data_full.drop(columns=['month'])\n",
    "\n",
    "print(\"Creating lag and rolling features...\")\n",
    "df_grouped = data_full.groupby(GROUP_COLUMN)\n",
    "lags = [1, 2, 3, 12]\n",
    "windows = [12]\n",
    "for lag in lags:\n",
    "    data_full[f'consumption_lag_{lag}m'] = df_grouped['consumption'].shift(lag)\n",
    "for window in windows:\n",
    "    rolling_feat = df_grouped['consumption'].rolling(window=window, min_periods=1).mean()\n",
    "    data_full[f'consumption_roll_mean_{window}m'] = rolling_feat.reset_index(level=0, drop=True)\n",
    "\n",
    "exog_cols = ['eur_per_mwh', 'avg_temp', 'avg_hum', 'wind', 'rain', 'air_pressure']\n",
    "for col in exog_cols:\n",
    "    if col in data_full.columns:\n",
    "        data_full[f'{col}_lag_12m'] = df_grouped[col].shift(12)\n",
    "\n",
    "# Create TARGET Features (Our 'y' variables)\n",
    "print(\"Creating 12 future-month target columns...\")\n",
    "HORIZON = 12\n",
    "target_cols = []\n",
    "for i in range(1, HORIZON + 1):\n",
    "    target_name = f'target_{i}m_ahead'\n",
    "    data_full[target_name] = df_grouped['consumption'].shift(-i)\n",
    "    target_cols.append(target_name)\n",
    "\n",
    "# Final Cleanup\n",
    "for col in static_cols:\n",
    "    data_full[col] = data_full[col].astype('category')\n",
    "\n",
    "# Define our final features list (used by all cells now)\n",
    "static_features = [col for col in data_full.columns if col in static_cols]\n",
    "dynamic_features = [\n",
    "    'year', 'month_sin', 'month_cos', 'num_holidays',\n",
    "    'consumption_lag_1m', 'consumption_lag_2m', 'consumption_lag_3m', 'consumption_lag_12m',\n",
    "    'consumption_roll_mean_12m',\n",
    "    'eur_per_mwh_lag_12m', 'avg_temp_lag_12m', 'avg_hum_lag_12m', \n",
    "    'wind_lag_12m', 'rain_lag_12m', 'air_pressure_lag_12m'\n",
    "]\n",
    "features = dynamic_features + static_features\n",
    "\n",
    "print(f\"--- Monthly Feature Engineering Complete ---\")\n",
    "data_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e34e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training with a non-leaking 17 feature set ---\n",
      "Training on 2022-01-01 00:00:00+00:00 to 2022-09-01 00:00:00+00:00\n",
      "Validating on 2022-10-01 00:00:00+00:00 to 2023-09-01 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "static_features = [col for col in data_full.columns if col in static_cols]\n",
    "\n",
    "dynamic_features = [\n",
    "    'year', 'month_sin', 'month_cos', 'num_holidays',\n",
    "    \n",
    "    'consumption_lag_12m',\n",
    "    'eur_per_mwh_lag_12m',\n",
    "    'avg_temp_lag_12m', 'avg_hum_lag_12m', 'wind_lag_12m',\n",
    "    'rain_lag_12m', 'air_pressure_lag_12m'\n",
    "]\n",
    "\n",
    "features = dynamic_features + static_features\n",
    "print(f\"--- Training with a non-leaking {len(features)} feature set ---\")\n",
    "\n",
    "# Create Train/Validation Split\n",
    "train_val_data = data_full.dropna(subset=features + target_cols)\n",
    "\n",
    "# Ensure the validation period is 12 months at the end\n",
    "val_cutoff = train_val_data[TIME_COLUMN].max() - pd.DateOffset(months=12)\n",
    "train = train_val_data[train_val_data[TIME_COLUMN] <= val_cutoff].copy()\n",
    "val = train_val_data[train_val_data[TIME_COLUMN] > val_cutoff].copy()\n",
    "\n",
    "print(f\"Training on {train[TIME_COLUMN].min()} to {train[TIME_COLUMN].max()}\")\n",
    "print(f\"Validating on {val[TIME_COLUMN].min()} to {val[TIME_COLUMN].max()}\")\n",
    "\n",
    "X_train = train[features]\n",
    "X_val = val[features]\n",
    "\n",
    "# Define the Optuna Objective Function\n",
    "TARGET_TO_TUNE = 'target_6m_ahead'\n",
    "y_train_tune = train[TARGET_TO_TUNE]\n",
    "y_val_tune = val[TARGET_TO_TUNE]\n",
    "\n",
    "tune_train_data = lgb.Dataset(X_train, label=y_train_tune, categorical_feature=static_features)\n",
    "tune_val_data = lgb.Dataset(X_val, label=y_val_tune, reference=tune_train_data)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'rmse',\n",
    "        'seed': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'n_estimators': 2000,\n",
    "        'feature_pre_filter': False,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 40),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0.1, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0.1, 10.0, log=True),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 30, 150),\n",
    "    }\n",
    "    model_tune = lgb.train(\n",
    "        params,\n",
    "        tune_train_data,\n",
    "        valid_sets=[tune_val_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "    )\n",
    "    return model_tune.best_score['valid_0']['rmse']\n",
    "\n",
    "# Run the Optuna Study\n",
    "print(f\"--- Starting Optuna Search (Tuning for {TARGET_TO_TUNE}) ---\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "print(\"--- Search Complete ---\")\n",
    "print(f\"Best Validation RMSE (for {TARGET_TO_TUNE}): {study.best_value:.2f}\")\n",
    "print(\"Best Parameters Found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1494830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training All 12 Models ---\n",
      "Training model for: target_1m_ahead\n",
      "Training model for: target_2m_ahead\n",
      "Training model for: target_3m_ahead\n",
      "Training model for: target_4m_ahead\n",
      "Training model for: target_5m_ahead\n",
      "Training model for: target_6m_ahead\n",
      "Training model for: target_7m_ahead\n",
      "Training model for: target_8m_ahead\n",
      "Training model for: target_9m_ahead\n",
      "Training model for: target_10m_ahead\n",
      "Training model for: target_11m_ahead\n",
      "Training model for: target_12m_ahead\n",
      "\n",
      "--- Training Complete: 12 models stored in 'model_pipeline' ---\n"
     ]
    }
   ],
   "source": [
    "# best_params = {'learning_rate': 0.08056583009280904, 'num_leaves': 21, 'subsample': 0.9525650463826345, 'colsample_bytree': 0.850318972819252, 'lambda_l1': 6.918875094886156, 'lambda_l2': 0.3219122718364551, 'min_child_samples': 37}\n",
    "\n",
    "# Get the best parameters from the study\n",
    "best_params = study.best_params\n",
    "\n",
    "# Set up final parameters\n",
    "final_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'rmse',\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1,\n",
    "    'n_estimators': 2000,\n",
    "    'feature_pre_filter': False,\n",
    "    **best_params  # Unpacks all the best params (lr, num_leaves, etc.)\n",
    "}\n",
    "\n",
    "# Train all 12 models in a loop\n",
    "print(\"--- Training All 12 Models ---\")\n",
    "model_pipeline = {} # This will hold our 12 models\n",
    "HORIZON = 12\n",
    "\n",
    "for i in range(1, HORIZON + 1):\n",
    "    target_name = f'target_{i}m_ahead'\n",
    "    print(f\"Training model for: {target_name}\")\n",
    "    \n",
    "    y_train_model = train[target_name]\n",
    "    y_val_model = val[target_name]\n",
    "    \n",
    "    train_data_model = lgb.Dataset(X_train, label=y_train_model, categorical_feature=static_features)\n",
    "    val_data_model = lgb.Dataset(X_val, label=y_val_model, reference=train_data_model)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        final_params,\n",
    "        train_data_model,\n",
    "        valid_sets=[val_data_model],\n",
    "        valid_names=['validation'],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Store the trained model\n",
    "    model_pipeline[i] = model\n",
    "\n",
    "print(\"\\n--- Training Complete: 12 models stored in 'model_pipeline' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17489c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Direct 12-Month Forecast (Corrected) ---\n",
      "Using historical lag features from 2024-09 for 112 groups.\n",
      "--- Direct Forecast Complete ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measured_at</th>\n",
       "      <th>group_id</th>\n",
       "      <th>consumption_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-01 00:00:00+00:00</td>\n",
       "      <td>738</td>\n",
       "      <td>389.766449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-01 00:00:00+00:00</td>\n",
       "      <td>740</td>\n",
       "      <td>109.972470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-01 00:00:00+00:00</td>\n",
       "      <td>393</td>\n",
       "      <td>244.508926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-01 00:00:00+00:00</td>\n",
       "      <td>708</td>\n",
       "      <td>333.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-01 00:00:00+00:00</td>\n",
       "      <td>225</td>\n",
       "      <td>197.170310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                measured_at  group_id  consumption_pred\n",
       "0 2024-10-01 00:00:00+00:00       738        389.766449\n",
       "1 2024-10-01 00:00:00+00:00       740        109.972470\n",
       "2 2024-10-01 00:00:00+00:00       393        244.508926\n",
       "3 2024-10-01 00:00:00+00:00       708        333.439418\n",
       "4 2024-10-01 00:00:00+00:00       225        197.170310"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"--- Starting Direct 12-Month Forecast (Corrected) ---\")\n",
    "\n",
    "# Get the last known row of data for EACH group\n",
    "latest_history_df = data_full.sort_values(by=TIME_COLUMN).groupby(GROUP_COLUMN).tail(1)\n",
    "\n",
    "# Extract the features that DON'T change (Lags, Statics)\n",
    "lag_features = [\n",
    "    'consumption_lag_1m', 'consumption_lag_2m', 'consumption_lag_3m', 'consumption_lag_12m',\n",
    "    'consumption_roll_mean_12m',\n",
    "    'eur_per_mwh_lag_12m', 'avg_temp_lag_12m', 'avg_hum_lag_12m', \n",
    "    'wind_lag_12m', 'rain_lag_12m', 'air_pressure_lag_12m'\n",
    "]\n",
    "base_features_df = latest_history_df[static_features + lag_features + [GROUP_COLUMN]]\n",
    "\n",
    "print(f\"Using historical lag features from {latest_history_df[TIME_COLUMN].max().strftime('%Y-%m')} for {len(base_features_df)} groups.\")\n",
    "\n",
    "# Create a list to hold our monthly forecast DataFrames\n",
    "forecast_dfs = []\n",
    "HORIZON = 12\n",
    "last_train_date = latest_history_df[TIME_COLUMN].max()\n",
    "\n",
    "# Loop 12 times and predict\n",
    "for i in range(1, HORIZON + 1):\n",
    "    model = model_pipeline[i]\n",
    "    \n",
    "    # The correct features for this future month\n",
    "    current_date = last_train_date + pd.DateOffset(months=i)\n",
    "    \n",
    "    # A new DataFrame for this month's features\n",
    "    X_future = base_features_df.copy()\n",
    "    \n",
    "    # The *correct* future time features for this month\n",
    "    X_future[TIME_COLUMN] = current_date\n",
    "    X_future['month'] = X_future[TIME_COLUMN].dt.month\n",
    "    X_future['year'] = X_future[TIME_COLUMN].dt.year\n",
    "    X_future['month_sin'] = np.sin(2 * np.pi * X_future['month'] / 12.0)\n",
    "    X_future['month_cos'] = np.cos(2 * np.pi * X_future['month'] / 12.0)\n",
    "    X_future['num_holidays'] = vectorized_holiday_count(X_future['year'], X_future['month'])\n",
    "    \n",
    "    X_future_final = X_future[features] \n",
    "    \n",
    "    predictions = model.predict(X_future_final)\n",
    "    \n",
    "    month_forecast_df = pd.DataFrame({\n",
    "        TIME_COLUMN: current_date,\n",
    "        GROUP_COLUMN: base_features_df[GROUP_COLUMN].values,\n",
    "        'consumption_pred': predictions\n",
    "    })\n",
    "    forecast_dfs.append(month_forecast_df)\n",
    "\n",
    "final_forecast_df = pd.concat(forecast_dfs)\n",
    "\n",
    "print(\"--- Direct Forecast Complete ---\")\n",
    "final_forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdeaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading true values from monthly_df_test.csv...\n",
      "\n",
      "Successfully merged 1344 rows for scoring.\n",
      "\n",
      "--- 12-Month Forecast Test Set Performance ---\n",
      "Final Test MAE:  822.12\n",
      "Final Test RMSE: 1006.91\n",
      "Final Test MAPE: 2.21\n"
     ]
    }
   ],
   "source": [
    "# Load the Test Set with True Values\n",
    "TEST_TRUTH_PATH = \"monthly_df_test.csv\"\n",
    "print(f\"Loading true values from {TEST_TRUTH_PATH}...\")\n",
    "test_true_df = pd.read_csv(TEST_TRUTH_PATH)\n",
    "\n",
    "# Convert 'measured_at' to datetime and *localize to UTC*\n",
    "test_true_df[TIME_COLUMN] = pd.to_datetime(test_true_df[TIME_COLUMN], utc=True)\n",
    "\n",
    "# Rename columns for a clean merge\n",
    "forecast_df_renamed = final_forecast_df.rename(columns={'consumption': 'consumption_pred'})\n",
    "test_true_df_renamed = test_true_df.rename(columns={'consumption': 'consumption_true'})\n",
    "\n",
    "# Merge Forecasts and True Values \n",
    "keys = [TIME_COLUMN, GROUP_COLUMN]\n",
    "score_df = pd.merge(\n",
    "    forecast_df_renamed[keys + ['consumption_pred']],\n",
    "    test_true_df_renamed[keys + ['consumption_true']],\n",
    "    on=keys,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Calculate and Print Final Scores\n",
    "if len(score_df) == 0:\n",
    "    print(\"\\n--- FATAL ERROR: Merge failed. No matching rows found. ---\")\n",
    "    print(\"Check that 'measured_at' (including UTC) and 'group_id' values match.\")\n",
    "elif len(score_df) < len(final_forecast_df):\n",
    "    print(f\"\\nWarning: Scored {len(score_df)} rows, but forecast had {len(final_forecast_df)} rows.\")\n",
    "    print(\"Some 'group_id's or 'measured_at' dates may not have been in the test file.\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully merged {len(score_df)} rows for scoring.\")\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(score_df['consumption_true'], score_df['consumption_pred'])\n",
    "rmse = np.sqrt(mean_squared_error(score_df['consumption_true'], score_df['consumption_pred']))\n",
    "mape = mean_absolute_percentage_error(score_df['consumption_true'], score_df['consumption_pred'])\n",
    "\n",
    "print(\"\\n--- 12-Month Forecast Test Set Performance ---\")\n",
    "print(f\"Final Test MAE:  {mae:.2f}\")\n",
    "print(f\"Final Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Final Test MAPE: {mape:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
